{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relevant imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import io\n",
    "from dotenv import load_dotenv\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from groq import Groq\n",
    "from sqlalchemy import create_engine, text, Result\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Create a Groq Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "client = Groq()\n",
    "# client = Groq(api_key=\"Your Key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Embedder**  \n",
    "Embedder model is used from sentence transformer  \n",
    "This is used for making semantic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embedder model\n",
    "# model = SentenceTransformer('all-mpnet-base-v2')\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Similarity Search**  \n",
    "This function makes the semantic similarity search of a string  \n",
    "It searches the strings that are closely related to search string by meanining  \n",
    "The reference strings re-ordered based on the similarity  \n",
    "If there is a distance threshold provided, only the ones relevant are provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_similarity_rank(\n",
    "    search_string: str,\n",
    "    sentences: list[str],\n",
    "    threshold: float = 0.0\n",
    ") -> tuple[list[str], list[int]]:\n",
    "    \"\"\"\n",
    "    Ranks sentences based on semantic similarity to the search_string.\n",
    "\n",
    "    Args:\n",
    "        search_string (str): The input query.\n",
    "        sentences (list[str]): List of sentences to compare.\n",
    "        threshold (float): Similarity threshold (0 means no threshold).\n",
    "\n",
    "    Returns:\n",
    "        tuple: (reordered_sentences, original_indexes)\n",
    "    \"\"\"\n",
    "\n",
    "    # Encode search string and sentence list\n",
    "    search_embedding = model.encode(search_string, convert_to_tensor=True)\n",
    "    sentence_embeddings = model.encode(sentences, convert_to_tensor=True)\n",
    "\n",
    "    # Compute cosine similarity score\n",
    "    cosine_scores = util.cos_sim(search_embedding, sentence_embeddings)[0]\n",
    "\n",
    "    # Pair sentences with scores and original indices\n",
    "    indexed_scores = [\n",
    "        (i, s, float(score)) for i, (s, score) in enumerate(zip(sentences, cosine_scores))\n",
    "        if threshold == 0.0 or float(score) >= threshold\n",
    "    ]\n",
    "\n",
    "    # Sort by score descending\n",
    "    indexed_scores.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "    # Extract reordered sentences and original indices\n",
    "    reordered_sentences = [s for _, s, _ in indexed_scores]\n",
    "    original_indexes = [i for i, _, _ in indexed_scores]\n",
    "\n",
    "    # Output the reordered senteces and the re-ordered indices in original set\n",
    "    return reordered_sentences, original_indexes\n",
    "    \n",
    "    # # Additional output\n",
    "    # scores = [sc[2] for sc in indexed_scores]\n",
    "    # return reordered_sentences, original_indexes, scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Let's try using it for sentence similarity search.  \n",
    ">Some sentences are provided with varied meaning  \n",
    ">See how it picks the relevance with search string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage of semantic similarity\n",
    "sentences = [\"Software update improved cloud data processing.\",\n",
    "                \"Researchers study atmospheric carbon capture.\",\n",
    "                \"Legislators debated new trade agreement's economic impact.\",\n",
    "                \"Personalized medicine targets cancer with genetics.\",\n",
    "                \"Oil price swings impact consumer spending.\",\n",
    "                \"Community programs address urban food deserts.\",\n",
    "                \"Adaptive learning boosts STEM student engagement.\",\n",
    "                \"Basel exhibition challenged art perceptions.\",\n",
    "                \"Heavy monsoon rains disrupted regional transport.\",\n",
    "                \"Court ruling set AI content IP precedent.\",\n",
    "                \"Optimizing supply chain cuts production costs.\",\n",
    "                \"Martian rover data hints at subsurface ice.\",\n",
    "                \"Phishing attack compromised corporate credentials.\",\n",
    "                \"Smart cities prioritize green transport.\",\n",
    "                \"Drought-resistant crops ensure food security.\",\n",
    "                \"Underdog team's win made sports headlines.\",\n",
    "                \"Pompeii finds reveal Roman daily life.\",\n",
    "                \"Sustainable tourism gains eco-conscious travelers.\",\n",
    "                \"Cognitive biases influence financial decisions.\",\n",
    "                \"Report found discrepancies in project spending.\"]\n",
    "\n",
    "search = 'AI is interesting'\n",
    "# search = 'It might rain tomorrow'\n",
    "\n",
    "# Make a meaning search\n",
    "sentence_re_ordered, index_re_oredered = semantic_similarity_rank (search, sentences)\n",
    "\n",
    "# Check the order of relevance\n",
    "# print (scores)\n",
    "print (index_re_oredered)\n",
    "for snt in sentence_re_ordered :\n",
    "\n",
    "    print (snt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['This phone has good battery', \n",
    "             'Laptop gets slow after a while',\n",
    "             'My PC is not very efficient',\n",
    "             'My smart phone has clarity of sound']\n",
    "\n",
    "search = 'Too much screen time is not good'\n",
    "\n",
    "# Make a meaning search\n",
    "sentence_re_ordered, index_re_oredered = semantic_similarity_rank (search, sentences)\n",
    "\n",
    "# Check the order of relevance\n",
    "# print (scores)\n",
    "print (index_re_oredered)\n",
    "for snt in sentence_re_ordered :\n",
    "\n",
    "    print (snt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Utility**  \n",
    "Util functions that are required for hadling CSV results  \n",
    "CSV format is chosen considering the number of rows that needs to be handled by LLM  \n",
    "if JSON, the context may be oversized and limits might hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_to_csv_string(result: Result, delimiter: str = ',') -> tuple[str, int]:\n",
    "    \"\"\"\n",
    "    Convert qeury result to CSV-formatted string.\n",
    "\n",
    "    Args:\n",
    "        result (Result): The result of conn.execute().\n",
    "        delimiter (str): Delimiter used in CSV (default is comma).\n",
    "\n",
    "    Returns:\n",
    "        tuple: (CSV string including headers, number of data rows)\n",
    "    \"\"\"\n",
    "\n",
    "    # Get column names\n",
    "    headers = result.keys()\n",
    "\n",
    "    # Get all rows\n",
    "    rows = result.fetchall()\n",
    "\n",
    "    # Use StringIO to build CSV string\n",
    "    output = io.StringIO()\n",
    "    writer = csv.writer(output, delimiter=delimiter)\n",
    "\n",
    "    # Write headers and data rows\n",
    "    writer.writerow(headers)\n",
    "    writer.writerows(rows)\n",
    "\n",
    "    csv_string = output.getvalue()\n",
    "    row_count = len(rows)\n",
    "\n",
    "    return csv_string, row_count\n",
    "\n",
    "\n",
    "def extract_column_from_csv(csv_text: str, column_name: str, delimiter: str = ',') -> list[str]:\n",
    "    \"\"\"\n",
    "    Extracts a column from CSV text as a list of strings based on the column header.\n",
    "\n",
    "    Args:\n",
    "        csv_text (str): The full CSV content as string.\n",
    "        column_name (str): The name of the column to extract.\n",
    "        delimiter (str): The CSV delimiter (default is ',').\n",
    "\n",
    "    Returns:\n",
    "        list[str]: List of values from the specified column.\n",
    "    \"\"\"\n",
    "    reader = csv.DictReader(io.StringIO(csv_text), delimiter=delimiter)\n",
    "    return [row[column_name] for row in reader if column_name in row]\n",
    "\n",
    "\n",
    "def filter_csv_rows_by_index(csv_text: str, row_indexes: list[int], delimiter: str = ',') -> str:\n",
    "    \"\"\"\n",
    "    Filters specific data rows from CSV text by their row index (excluding the header row).\n",
    "\n",
    "    Args:\n",
    "        csv_text (str): The full CSV content as string.\n",
    "        row_indexes (list[int]): List of 0-based row numbers (excluding header).\n",
    "        delimiter (str): The CSV delimiter (default is ',').\n",
    "\n",
    "    Returns:\n",
    "        str: New CSV string with only selected rows (including header).\n",
    "    \"\"\"\n",
    "    reader = csv.reader(io.StringIO(csv_text), delimiter=delimiter)\n",
    "    rows = list(reader)\n",
    "    \n",
    "    if not rows:\n",
    "        return \"\"\n",
    "\n",
    "    header = rows[0]\n",
    "    data_rows = rows[1:]\n",
    "\n",
    "    selected_rows = [data_rows[i] for i in row_indexes if 0 <= i < len(data_rows)]\n",
    "\n",
    "    output = io.StringIO()\n",
    "    writer = csv.writer(output, delimiter=delimiter)\n",
    "    writer.writerow(header)\n",
    "    writer.writerows(selected_rows)\n",
    "\n",
    "    return output.getvalue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions**\n",
    "Query instruction is adapted to consider the product choice of user along with question / prompt  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_Instr = \"Using the context given, provide response to the user question or statement.\\\n",
    "            Context is provided as CSV formatted string.\\\n",
    "            Answer to the question with details\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">SQLite Engine with connection created  \n",
    ">The product catalogue database is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is an engine instance created, which can handle multiple connetions\n",
    "DB_File = \"Sample_3 - Copy.db\"\n",
    "\n",
    "if os.path.exists (DB_File):\n",
    "    sql_engine = create_engine(\"sqlite:///\"+DB_File)\n",
    "    conn = sql_engine.connect ()\n",
    "else:\n",
    "    print (\"DB Files does not exist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Product category**  \n",
    "From the user query, identify product category by making semantic search  \n",
    "The distinct values of the product type is matched to the user prompt  \n",
    "Depending on if there is a relevant product type (threshold is given) the product selection is made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt = \"I need a ear phone which has durable battery\"\n",
    "Prompt = \"Give me some latest monitor that has good brightness\"\n",
    "# Prompt = \"Can you suggest me a Phone that has sensitive touch screen and durable battery?\"\n",
    "# Prompt = \"Which is the good TV?\"\n",
    "\n",
    "# Identify Product type by semantic search\n",
    "result = conn.execute (text(f\"\"\"\n",
    "                            SELECT DISTINCT Product_Type from product_catalogue\n",
    "                              \"\"\"))\n",
    "\n",
    "# Get the Product categories from database and make it into a list\n",
    "rows = result.fetchall()\n",
    "Categories = [str(row[0]) for row in rows]\n",
    "# print (Categories)\n",
    "\n",
    "Shortlist, Order = semantic_similarity_rank (Prompt, Categories, 0.3)\n",
    "Shortlist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Query**  \n",
    "Filter based on the product type that is identified.  \n",
    "The result is then fed for further semantic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query from DB for the Product type that is identified\n",
    "result = conn.execute (text(f\"\"\"\n",
    "                            SELECT * from product_catalogue WHERE Product_Type = '{Shortlist[0]}'\n",
    "                              \"\"\"))\n",
    "\n",
    "# The output is then convereted into CSV text\n",
    "CSV_Result, Nb_Rows = result_to_csv_string (result)\n",
    "print (Nb_Rows)\n",
    "\n",
    "# Extract the User Feedback Column\n",
    "Feedback = extract_column_from_csv (CSV_Result, 'User_Feedback')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Semantic Search**  \n",
    "Since the feedback column is textual data, semantic searach is applied to identify the relevant ones  \n",
    "Top k numbers are then filtered based on the re-ordered ranking  \n",
    "This is used as context to LLM for answering user query  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many to be filtered\n",
    "top_k = 10\n",
    "\n",
    "# Make semantic similarity in feedback column and get the order by relevance\n",
    "Shortlist, Order = semantic_similarity_rank (Prompt, Feedback)\n",
    "print (Order)\n",
    "\n",
    "# Filter out the required numbers. this is the indices that is required after the re-ordering\n",
    "Filter = Order[:top_k]\n",
    "\n",
    "# Filter the CSV content by required row numbers\n",
    "Context = filter_csv_rows_by_index (CSV_Result, Filter)\n",
    "# print (Context)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LLM answer**\n",
    "With the context that is categorically and semantically filtered, it is then provided to LLM  \n",
    "Along with this context user query is responded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=[\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": R_Instr\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\":\"Context : \\n\"+ Context + \"Query : \\n\" + Prompt\n",
    "    }\n",
    "]\n",
    "completion = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=\"openai/gpt-oss-120b\",\n",
    ")\n",
    "\n",
    "print (completion.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tab_RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
