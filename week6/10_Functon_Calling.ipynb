{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Calling\n",
    "\n",
    "**Function Calling** / tool calling is a feature provided by LLM models to integrate specific tools when user prompts  \n",
    "This becomes handy when we build a RAG pipeline with structured data  \n",
    "Structured data RAG typically requires multiple pass to LLM, hence this feature will be helpful  \n",
    "\n",
    "**Mechanism**\n",
    ">In short the mechanism of funtion call revolves around providing a specific tool as a function for LLM to use  \n",
    ">Define the feature / functionality you want to provide as a capability to LLM as a function  \n",
    ">Provide the details of purpose and usage, which can be interpreted by LLM  \n",
    ">When user prompts, LLM will take a call to use the tool based on the need and description provided  \n",
    ">The output from tool then integrated as additional data to respond to the prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Relevant Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text, Result\n",
    "import json\n",
    "import csv\n",
    "from groq import Groq\n",
    "from dotenv import load_dotenv\n",
    "import io\n",
    "import openai\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Connection and Model**  \n",
    "Create SQL Engine connection to the SQLite database  \n",
    "Groq models support function calling features as well  \n",
    "The API interface is similar with OpenAI  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv ()\n",
    "DB_File = \"Sample_2 - Copy.db\"\n",
    "\n",
    "if os.path.exists (DB_File):\n",
    "    sql_engine = create_engine(\"sqlite:///\"+DB_File)\n",
    "    conn = sql_engine.connect ()\n",
    "else:\n",
    "    print (\"DB Files does not exist\")\n",
    "\n",
    "client = Groq()\n",
    "# client = Groq(api_key=\"Your Key\")\n",
    "model = \"llama-3.3-70b-versatile\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CSV Util**  \n",
    "Function to covert the SQL query result into CSV formatted text  \n",
    "In case of function calling multiple interaction might happen with LLM & more data would go in message  \n",
    "Its important to have information compacted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_to_csv_string(result: Result, delimiter: str = ',') -> tuple[str, int]:\n",
    "    \"\"\"\n",
    "    Convert qeury result to CSV-formatted string.\n",
    "\n",
    "    Args:\n",
    "        result (Result): The result of conn.execute().\n",
    "        delimiter (str): Delimiter used in CSV (default is comma).\n",
    "\n",
    "    Returns:\n",
    "        tuple: (CSV string including headers, number of data rows)\n",
    "    \"\"\"\n",
    "\n",
    "    # Get column names\n",
    "    headers = result.keys()\n",
    "\n",
    "    # Get all rows\n",
    "    rows = result.fetchall()\n",
    "\n",
    "    # Use StringIO to build CSV string\n",
    "    output = io.StringIO()\n",
    "    writer = csv.writer(output, delimiter=delimiter)\n",
    "\n",
    "    # Write headers and data rows\n",
    "    writer.writerow(headers)\n",
    "    writer.writerows(rows)\n",
    "\n",
    "    csv_string = output.getvalue()\n",
    "    row_count = len(rows)\n",
    "\n",
    "    return csv_string, row_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function definiton**  \n",
    "The function definition for fetching SQL data and provide as output  \n",
    "This will be called by LLM upon providing required information and based on need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Data (SQL_Query : str) -> str:\n",
    "\n",
    "    \"\"\" \n",
    "    This function provides data extracted from SQL database.\n",
    "    Provided the SQL query, it fetches the data and returns it as CSV formatted string\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Query from DB for the provided SQL query\n",
    "        result = conn.execute (text(SQL_Query))\n",
    "\n",
    "        # The output is then convereted into CSV text\n",
    "        CSV_Result, Nb_Rows = result_to_csv_string (result)\n",
    "\n",
    "        # Return the query result ass CSV text\n",
    "        # print (CSV_Result)\n",
    "        return CSV_Result\n",
    "\n",
    "    except Exception:\n",
    "        return (\"Error while fetching the data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Toolkit**  \n",
    "Provide information about the function as a 'Tool'  \n",
    "This shall clearly state function name, arguments, functional description etc  \n",
    "There can be multiple tools provided in the tool kit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool definition of function in a specific format as dict\n",
    "# this provides details about function signature, so that LLM can understand the purpose of tool and how to use it\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"Get_Data\",\n",
    "            \"description\": \"Fetches data from SQLite database for a provided SQL query. Returns the data in CSV formatted text\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"SQL_Query\": {\"type\": \"string\", \"description\" : \"SQL query to get the data\"},\n",
    "                },\n",
    "                \"required\": [\"SQL_Query\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Schema**\n",
    "Schema provided in CSV formatted text with sample data  \n",
    "Sample data will help the LLM to understand the database better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Schema = \"\"\"\n",
    "Column_Name,Type,Sample_Content\n",
    "student_id,VARCHAR(50),S1000\n",
    "age,INTEGER,23\n",
    "gender,VARCHAR(50),Female\n",
    "study_hours_per_day,REAL,0.0\n",
    "social_media_hours,REAL,1.2\n",
    "netflix_hours,REAL,1.1\n",
    "part_time_job,VARCHAR(50),No\n",
    "attendance_percentage,REAL,85.0\n",
    "sleep_hours,REAL,8.0\n",
    "diet_quality,VARCHAR(50),Fair\n",
    "exercise_frequency,INTEGER,6\n",
    "parental_education_level,VARCHAR(50),Master\n",
    "internet_quality,VARCHAR(50),Average\n",
    "mental_health_rating,INTEGER,8\n",
    "extracurricular_participation,VARCHAR(50),Yes\n",
    "exam_score,REAL,56.2\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instruction**  \n",
    "Instruction adapted to provide task to be done and tool usage  \n",
    "specific instructions for SQL also provided  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_Instr = \"\"\"\n",
    "           You are an SQL expert and helpful assistant.\n",
    "           Answer to the question based on the data available through the tool.\n",
    "           From the schema and table name given, understand the table structure clearly.\n",
    "           Use the tool to fetch the required data to answer user question.\n",
    "           Provide response based on data.\n",
    "           \n",
    "           **Instructions**:            \n",
    "           Use your SQL expertise and write efficient queries.\n",
    "           Query for required information.\n",
    "           Its SQLite DB. Schema is provided as comma seperated text.\n",
    "           When you use Text fields, always convert to lower case and use wild card : %xxx% \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Invoke LLM with tool**  \n",
    "While invoking LLM, along with instructions and prompt, the toolkit data is provided  \n",
    "Depending on need, LLM uses the tool by tool call  \n",
    "Tool call is resolved by code again and result passed on to LLM  \n",
    "LLM provides response based on query and data fed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prompt = \"Average score of girls whose parents have done masters\"\n",
    "# Prompt = \"How much on an average boys spend online?\"\n",
    "# Prompt = \"Who spends more time on line - Boys or Girls?\"\n",
    "# Prompt = \"What do students with higher score do differently?\"\n",
    "\n",
    "# First stage message with prompt and instructions\n",
    "messages = [\n",
    "        {\"role\": \"system\", \n",
    "         \"content\": R_Instr},\n",
    "        \n",
    "        {\"role\": \"system\", \n",
    "         \"content\": \"Table Name : Student_Performance \\n Schema :\\n\"+Schema},\n",
    "        \n",
    "        {\"role\": \"user\", \n",
    "         \"content\": Prompt}\n",
    "]\n",
    "\n",
    "# Invoke includes the tool kit\n",
    "response = client.chat.completions.create(    \n",
    "    model=model,\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\"\n",
    ")\n",
    "\n",
    "# Check the message received at this stage\n",
    "msg = response.choices[0].message\n",
    "print (msg)\n",
    "\n",
    "# Resolve the tool call from the 1st response \n",
    "if msg.tool_calls:\n",
    "    \n",
    "    # Depending on question LLM may place multiple tool call request\n",
    "    for tool_call in msg.tool_calls :    \n",
    "        \n",
    "        # extract the arguments (in our case, that's the SQL query)\n",
    "        args = json.loads(tool_call.function.arguments)\n",
    "        function = globals()[tool_call.function.name]\n",
    "        result = function(**args)\n",
    "\n",
    "        # Include the query result in the context and invoke LLM again (2nd stage)\n",
    "        messages.append(msg)\n",
    "        messages.append({\n",
    "            \"role\": \"tool\",\n",
    "            \"tool_call_id\": tool_call.id,\n",
    "            \"name\": tool_call.function.name,\n",
    "            \"content\": str(result)\n",
    "        })\n",
    "\n",
    "    # Final output\n",
    "    final_response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    print(final_response.choices[0].message.content)\n",
    "else:\n",
    "    print(msg.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tab_RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
