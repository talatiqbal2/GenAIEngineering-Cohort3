{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Required imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import jmespath\n",
    "from dotenv import load_dotenv\n",
    "from groq import Groq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the JSON File**  \n",
    "Lod the JSON file which has survey data arranged in multi level nesting  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON data from file\n",
    "with open(\"survey_data.json\", \"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Key nesting is used as part of query.  \n",
    ">Filter done at innesr most level (records)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for volunteers in Jordan with education \"High School\"\n",
    "query = \"Jordan.volunteers[?education=='High School']\"\n",
    "results = jmespath.search(query, data)\n",
    "\n",
    "# Print the filtered records\n",
    "for person in results:\n",
    "    print(person)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Loop through at a level, to retain value of that field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract names of urban residents per country\n",
    "urban_names_per_country = {}\n",
    "\n",
    "# Loop through the outer dimension\n",
    "for country, info in data.items():\n",
    "    #query to get names of volunteers living in urban areas\n",
    "    query = \"volunteers[?location_type=='Urban'].name\"\n",
    "    names = jmespath.search(query, info)\n",
    "    urban_names_per_country[country] = names\n",
    "\n",
    "urban_names_per_country\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to hold results\n",
    "phd_demographics_per_country = {}\n",
    "\n",
    "# Apply JMESPath filter for each country\n",
    "for country, info in data.items():\n",
    "    result = jmespath.search(\"volunteers[?education=='PhD'][].{age: age, sex: sex}\", info)\n",
    "    if result:  # Only store countries with PhD individuals\n",
    "        phd_demographics_per_country[country+' - PhD'] = result\n",
    "\n",
    "phd_demographics_per_country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Retrived Data to LLM**  \n",
    "The data retrieved from JSON is provided to LLM as context  \n",
    "This provides the relevant data to respond to the prompt  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "client = Groq()\n",
    "# client = Groq(api_key=\"Your Key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Specific instuction for Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_Instr = \"Using the context given, provide response to the user question or statement.\\\n",
    "            Context is provided in JSON format.\\\n",
    "            Provide a comprehensive response\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The data is being retireved from JSON using list comprehension  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User prompt\n",
    "Prompt = \"Who is more educated, in each country? Ladies or Gents?\"\n",
    "\n",
    "# Filter out only relevant fields\n",
    "filtered_data = {\n",
    "    country: [\n",
    "        {\"sex\": v[\"sex\"], \"education\": v[\"education\"]}\n",
    "        for v in info[\"volunteers\"]\n",
    "    ]\n",
    "    for country, info in data.items()\n",
    "}\n",
    "\n",
    "Context = json.dumps (filtered_data)\n",
    "\n",
    "# Invoke LLM with prompt and context\n",
    "messages=[\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": R_Instr\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\":\"Context : \\n\"+ Context\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Query : \\n\" + Prompt\n",
    "    }\n",
    "]\n",
    "completion = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=\"openai/gpt-oss-120b\",\n",
    ")\n",
    "\n",
    "print (completion.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tab_RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
